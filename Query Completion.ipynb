{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read queries\n",
    "queries_json = json.load(open( \".\\cranfield\\cran_queries.json\", 'r'))[:]\n",
    "query_ids, queries = [item[\"query number\"] for item in queries_json], \\\n",
    "                        [item[\"query\"] for item in queries_json]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# queries_sent = [query.split('.') for query in queries]\n",
    "# queries_sent\n",
    "query_merged = ''.join(queries)\n",
    "queries_sent = query_merged.split('.')\n",
    "queries_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(queries_sent)\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for query in queries_sent:\n",
    "    sequence = tokenizer.texts_to_sequences([query])[0]\n",
    "    for i in range(1,len(sequence)):\n",
    "        input_sequences.append(sequence[:i+1])\n",
    "        \n",
    "# pad sequences to equal length\n",
    "max_seq_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_seq_len, padding = 'pre'))\n",
    "\n",
    "# create predictors and labels\n",
    "xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "\n",
    "total_words = len(tokenizer.word_index)+1\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes = total_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 16, input_length = max_seq_len -1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(xs, ys, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert number to string associated with the label\n",
    "reverse_word_index = {val : key for (key,val) in tokenizer.word_index.items()}\n",
    "reverse_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_query(incomplete_query, next_n_words = 1):\n",
    "    seed_text = incomplete_query\n",
    "    next_words = next_n_words\n",
    "    \n",
    "    for _ in range(next_words):\n",
    "        \n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen = max_seq_len - 1, padding = 'pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        # print(predicted)\n",
    "        # decoding the predicted word\n",
    "        out_word = reverse_word_index[predicted[0]]\n",
    "        seed_text += \" \"+out_word\n",
    "        \n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_query(\"experimental studies of creep\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_query(\"experimental studies of creep\",10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
